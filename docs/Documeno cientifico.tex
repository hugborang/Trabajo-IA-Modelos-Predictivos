\documentclass[conference,a4paper]{IEEEtran}

% Escritura mejorada de fórmulas matemáticas
\usepackage{amsmath}

% Inserción de gráficos
\usepackage{graphicx}

% Escritura de pseudocódigo
\usepackage{kbordermatrix}
\usepackage{amsmath}
\usepackage{graphicx}

% Escritura mejorada de tablas
\usepackage{booktabs}

% Escritura mejorada de citas bibliográficas
\usepackage{cite}

\begin{document}

\title{Título del trabajo (elegir uno original)}

\author{
  \IEEEauthorblockN{Hugo Borrego Angulo}
  \IEEEauthorblockA{
    \textit{Dpto. Ciencias de la Computación e Inteligencia Artificial}\\
    \textit{Universidad de Sevilla}\\
    Sevilla, España\\
    Correos electrónicos UVUS y de contacto (si distinto)}
  
  \and
  
  \IEEEauthorblockN{Rafael Duque Colete}
  \IEEEauthorblockA{
    \textit{Dpto. Ciencias de la Computación e Inteligencia Artificial}\\
    \textit{Universidad de Sevilla}\\
    Sevilla, España\\
    Correos electrónicos UVUS y de contacto (si distinto)}
}

\maketitle

\begin{abstract}
  En este trabajo se presenta una propuesta para la selección de características,
  basada en la utilización de dos algoritmos de búsqueda: \emph{búsqueda secuencial hacia atrás} y
  \emph{búsqueda secuencial hacia atrás mixta}. 
  Estos algoritmos se han aplicado a dos conjuntos de datos referentes a: \emph{titanic} y \emph{breast cancer}.

  Una vez obtenidos los resultados y con ello las características seleccionadas, se han aplicado 2 algoritmos de 
  entrenamiento: \emph{DecisionTreeClassifier} y \emph{Naive Bayes}. Con los que podemos evaluar las soluciones
  que nos proporcionan los algoritmos de búsqueda anteriormente mencionados.
\end{abstract}

\begin{IEEEkeywords}
  Inteligencia Artificial, otras palabras clave…
\end{IEEEkeywords}

\section{Introducción}
En la actualidad, la selección de características es una técnica fundamental en el análisis de datos y el aprendizaje automático
utilizado en el campo de la Inteligencia Artificial. La selección de características nos ayuda en el preprocesamiento de
datos, ya que ayuda a reducir la dimensionalidad de los datos, mejorar la precisión de los modelos y facilitar la interpretación
de los resultados.

Una vez que los datos han sido adecuadamente preprocesados, la selección de características nos ayudará a mejorar 
la eficiencia y la interpretabilidad de los modelos. Los algoritmos de búsqueda secuencial hacia atrás y búsqueda secuencial hacia atrás 
mixta son técnicas para la selección de estas características. Estos algoritmos eliminan iterativamente las características menos
relevantes, con el objetivo de identificar un subconjunto óptimo de características que maximicen el rendimiento predictivo.

En este trabajo, se aplica un enfoque sistemático para analizar y comparar el rendimiento de dos modelos de clasificación.  
El Decision Tree Classifier y el Naive Bayes, en los conjuntos de datos del Titanic y Breast Cancer. Se evaluará cómo la 
selección de características mediante los algoritmos mencionados influye en el rendimiento de estos modelos.

Este trabajo tiene como objetivo principal explorar y demostrar la efectividad de diversas técnicas de preprocesamiento y selección de
características en la mejora del rendimiento de modelos de clasificación. Los resultados obtenidos proporcionarán una comprensión más
profunda de las mejores prácticas para el manejo y análisis de datos en contextos similares y destacarán la importancia de un preprocesamiento
adecuado y una selección de características rigurosa en la construcción de modelos predictivos robustos.

\section{Preliminares}

Para comprender el trabajo realizado, es necesario conocer los conceptos básicos de la selección de características y los algoritmos,
que ha sido utilizados en este trabajo.

\subsection{Métodos empleados}

   \subsection*{Tratamiento de datos}
    \begin{itemize}
      \item Normalización: Se ha aplicado la normalización a los datos que era necesario, con el objetivo de que todas las variables 
      tengan la misma escala.
      \item Codificación de variables categóricas: Se ha aplicado la codificación de variables categóricas a los datos que era necesario,
       con el objetivo de que todas las variables sean numéricas.
    \end{itemize}

    \subsection*{Algoritmos de selección de características}
    \begin{itemize}
      \item Búsqueda secuencial hacia atrás: Este algoritmo elimina iterativamente las características menos relevantes, con el objetivo 
      de identificar un subconjunto óptimo de características que maximicen el rendimiento predictivo.
      \item Búsqueda secuencial hacia atrás mixta: Este algoritmo elimina iterativamente las características menos relevantes, y añade las
      características más relevantes, con el objetivo de identificar un subconjunto óptimo de características que maximicen el rendimiento predictivo.
    \end{itemize}

    \subsection*{Algoritmos de entrenamiento}
    \begin{itemize}
      \item Decision Tree Classifier: Este algoritmo es un método de aprendizaje supervisado que se utiliza para la clasificación y regresión.
      \item Naive Bayes: Este algoritmo es un método de aprendizaje supervisado que se utiliza para la clasificación. 
    \end{itemize}


\section{Metodología}

A continuación, un ejemplo de uso de listas numeradas:
\begin{enumerate}
  \item\label{item:dos-alumnos} \textit{Trabajos con dos alumnos:} poner nombre y
  apellidos completos de cada uno, y correos electrónicos de contacto (a ser
  posible de la Universidad de Sevilla). El orden de los alumnos se fijará por
  orden alfabético según los apellidos.
\end{enumerate}

Para el desarrollo de este trabajo se han implementado los algoritmos de búsqueda secuencial 
hacia atrás y búsqueda secuencial hacia atrás mixta.
Todo esto en el lenguaje de programación Python, utilizando las librerías de Scikit-learn y Pandas.

\subsection{Funciones implementadas}

  \subsubsection*{Método Robust Evaluation}

  Para ambos métodos se ha usado la función \emph{robust\_evaluation} que hace uso del método
  \emph{cross\_val\_score} de la librería Scikit-learn, esta función nos permitirá realizar 
  evaluaciones mediante validación cruzada.
  Respecto a la función \emph{robust\_evaluation} está nos permitirá evaluar el rendimiento de los subconjuntos
  de variables predictoras seleccionadas, siendo necesario para su uso:
  \begin{enumerate}
    \item X: El conjunto de datos con todas las variables predictoras.
    \item y: El conjunto de datos con la variable objetivo.
    \item model: El modelo de clasificación que se va a evaluar.
    \item N\_Exp: El número de repeticiones del experimento por validación cruzada.
    \item cV: El número de pliegues del conjunto de datos para la validación cruzada.
  \end{enumerate}
  Devolviendo el promedio de las N\_Exp evaluaciones realizadas por la función \emph{cross\_val\_score}, usando como
  medida de rendimiento la tasa de acierto balanceada.

  \subsubsection*{Búsqueda secuencial hacia atrás} 
  Esta función nos proporcionará una tabla con los subconjuntos de variables predictoras, su rendimiento, y 
  número de variables predictoras seleccionadas.
  Para su uso es necesario:
  \begin{enumerate}
    \item X: El conjunto de datos con todas las variables predictoras y la variable objetivo.
    \item objective: El nombre de la variable objetivo.
    \item model: El modelo de clasificación que se va a evaluar.
    \item N\_Exp: El número de repeticiones del experimento por validación cruzada.
    \item cV: El número de pliegues del conjunto de datos para la validación cruzada.
  \end{enumerate}
  Una vez sabemos que es necesario para su uso pasamos a la explicación de dicho algoritmo.
  En primer lugar, se inicializa el conjunto de variables predictoras con todas las variables predictoras,
  y otro con la variable respuesta. Además de una lista vacía que contendrá el resultado, y una solución
  actual que contendrá las variables predictoras seleccionadas.

  A continuación, se realizará el siguiente proceso k veces, siendo k el número de variables predictoras menos.
  \begin{enumerate}
    \item Se eliminan variables de la solución actual una por una.
    \item Se aplicará la función \emph{robust\_evaluation} sobre conjunto de variables predictoras actualizado.
    \item Se guardará el mejor rendimiento de entre todos los subconjuntos de variables predictoras, además de la peor variable.
    \item Se elimina de la solución actual la peor variable.
    \item Se añade la solución actual el conjunto de variables que proporcionó el mejor rendimiento al resultado.
    \item Se vuelve al inicio del bucle si este no ha sido ejecutado k veces.
    \item Por último añadimos al resultado el rendimiento de el conjunto de variables predictoras completo.
    \item Devolvemos un DataFrame con el resultado.
  \end{enumerate}

  \subsubsection*{Búsqueda secuencial hacia atrás mixta} 
  Esta función nos proporcionará un DataFrame con los subconjuntos el de variables predictoras, su rendimiento, y 
  número de variables predictoras seleccionadas.
  Para su uso es necesario:
  \begin{enumerate}
    \item X: El conjunto de datos con todas las variables predictoras y la variable objetivo.
    \item objective: El nombre de la variable objetivo.
    \item model: El modelo de clasificación que se va a evaluar.
    \item N\_Exp: El número de repeticiones del experimento por validación cruzada.
    \item cV: El número de pliegues del conjunto de datos para la validación cruzada.
    \item M: Número de iteraciones una vez se hayan eliminado todas las variables predictoras, 
    y además no se añade ninguna variable predictora.
  \end{enumerate}
  Una vez sabemos que es necesario para su uso pasamos a la explicación de dicho algoritmo.
  En primer lugar, se inicializa el conjunto de variables predictoras con todas las variables predictoras,
  y otro con la variable respuesta. Además de una lista vacía que contendrá el resultado, y una solución
  actual que contendrá las variables predictoras seleccionadas.

  Luego mientras se cumpla la condición de parada, la cuál será que el conjunto de variables predictoras haya sido 
  eliminadas al menos 1 vez y una vez esto se cumpla el bucle haya tenido al menos M iteraciones, siempre y cuando 
  no se añada ninguna variable predictora, se realizará el siguiente proceso:
  \begin{enumerate}
    \item Se eliminan variables de la solución actual una por una.
    \item Se aplicará la función \emph{robust\_evaluation} sobre el conjunto de variables predictoras actualizado.
    \item Se guardará el mejor rendimiento de entre todos los subconjuntos de variables predictoras, además de la peor variable.
    \item Se elimina de la solución actual la peor variable y se añade a la lista de eliminadas.
    \item Se añaden variables de la solución actual una por una, siempre que estas no estén ni en la lista de eliminados ni en la solución actual.
    \item Se aplicará la función \emph{robust\_evaluation} sobre el conjunto de variables predictoras actualizado.
    \item Se guardará el mejor rendimiento de entre todos los subconjuntos de variables predictoras si este supera el rendimiento ya calculado anteriormente, además de la mejor variable.
    \item Por último se añade la solución actual el conjunto de variables que proporcionó el mejor rendimiento al resultado.
    \item Devolvemos un DataFrame con el resultado.
  \end{enumerate}

Las figuras se deben mencionar en el texto, como la
\figurename~\ref{fig:ejemplo}.

\figurename~\ref{pcd:búsqueda secuencial hacia atrás}.
\begin{figure}
  \begin{pseudo}*
    \hd{\fn{búsqueda hacia atrás con evaluación robusta}}(SolucionInicial) \\*
    \multicolumn{2}{l}{\textbf{Entrada}: DataFrame con todas las variables \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: Nombre de la variable respuesta \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: model, tipo de tarea \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: Número de repeticiones del experimento por validación cruzada \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: Número de pliegues a considerar por la validación cruzada \( SolucionInicial \)} \\*
    
    \multicolumn{2}{l}{\textbf{Salida}: una tabla con \( K \) soluciones, su tamaño y rendimiento} \\

    \( K \leftarrow \textnormal{tamaño de } SolucionInicial \) \\
    \( Tabla \leftarrow \textnormal{vacía} \) \\
    \( PeorVariable \leftarrow \textnormal{vacía} \) \\

    \por cada \( k \) \textnormal{ desde } \( K \) \textnormal{ hasta } \( 1 \) \textnormal{ hacer} \\+
        \( MejorRendimiento \leftarrow -\infty \) \\
        \( MejorSolucionTemporal \leftarrow \textnormal{vacía} \) \\

        \por cada \( V \) \textnormal{ en } \( SolucionActual \) \textnormal{ hacer} \\+
            \( SolucionTemporal \leftarrow SolucionActual - V \) \\
            \( Rendimiento \leftarrow \fn{evaluacionRobusta}(SolucionTemporal) \) \\

            \si \( Rendimiento > MejorRendimiento \) \textnormal{ entonces} \\+
                \( MejorRendimiento \leftarrow Rendimiento \) \\
                \( PeorVariable \leftarrow V \) \\-
        \fin \\-

        \( SolucionActual \leftarrow SolucionActual - PeorVariable \) \\
        \( Tabla \leftarrow \fn{agregarFila}(Tabla, MejorSolucionTemporal, \textnormal{tamaño}(MejorSolucionTemporal), MejorRendimiento) \) \\-
    \fin \\

    \( Tabla \leftarrow \fn{ordenarPorRendimiento}(Tabla) \) \\
    \( DataFrame \leftarrow \fn{convertirADataFrame}(Tabla) \) \\

    \devolver \( DataFrame \) \\
  \end{pseudo}
\end{figure}

\figurename~\ref{fig:ejemplo}.
\figurename~\ref{pcd:búsqueda secuencial hacia atrás mixta}.
\begin{figure}
  \begin{pseudo}*
    \hd{\fn{búsqueda hacia atrás mixta}}(SolucionInicial) \\*
    \multicolumn{2}{l}{\textbf{Entrada}: DataFrame con todas las variables \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: Nombre de la variable respuesta \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: model, tipo de tarea \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: Número de repeticiones del experimento por validación cruzada \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: Número de pliegues a considerar por la validación cruzada \( SolucionInicial \)} \\*
    \multicolumn{2}{l}{\textbf{Entrada}: Número de iteraciones una vez se hayan eliminado todas las variables predictoras, y además no se añade ninguna variable predictora \( SolucionInicial \)} \\
    
    \multicolumn{2}{l}{\textbf{Salida}: una tabla con \( K \) soluciones, su tamaño y rendimiento} \\

    \( K \leftarrow \textnormal{tamaño de } SolucionInicial \) \\
    \( Solucion \leftarrow \textnormal{vacía} \) \\
    \( Eliminados \leftarrow \textnormal{vacía} \) \\
    \( Añadidos \leftarrow \textnormal{vacía} \) \\
    \( PeorVariable \leftarrow \textnormal{vacía} \) \\

    \por cada \( k \) \textnormal{ desde } \( K \) \textnormal{ hasta } \( 1 \) \textnormal{ hacer} \\+
        \( MejorRendimiento \leftarrow -\infty \) \\
        \( MejorSolucionTemporal \leftarrow \textnormal{vacía} \) \\

        \por cada \( V \) \textnormal{ en } \( SolucionActual \) \textnormal{ hacer} \\+
            \( SolucionTemporal \leftarrow SolucionActual - V \) \\
            \( Rendimiento \leftarrow \fn{evaluacionRobusta}(SolucionTemporal) \) \\

            \si \( Rendimiento > MejorRendimiento \) \textnormal{ entonces} \\+
                \( MejorRendimiento \leftarrow Rendimiento \) \\
                \( PeorVariable \leftarrow V \) \\-
        \fin \\-
        \( Eliminados \leftarrow Eliminados + PeorVariable \) \\


        \por cada \( V \) \textnormal{ en } \( ConjuntoOriginal \) \textnormal{ hacer} \\+
            \si \( V \textnormal{ no está en } SolucionActual \textnormal{ ni en } Añadidos \) \textnormal{ entonces} \\+
                \( SolucionTemporal \leftarrow SolucionActual + V \) \\
                \( Rendimiento \leftarrow \fn{evaluacionRobusta}(SolucionTemporal) \) \\

                \si \( Rendimiento > MejorRendimiento \) \textnormal{ entonces} \\+
                    \( MejorRendimiento \leftarrow Rendimiento \) \\
                    \( MejorSolucionTemporal \leftarrow SolucionTemporal \) \\-
            \fin \\-
        \fin \\-

        \si \( MejorRendimiento > MejorRendimientoPunto2 \) \textnormal{ entonces} \\+
            \( SolucionActual \leftarrow MejorSolucionTemporal \) \\
            \( Añadidos \leftarrow \fn{agregar}(Añadidos, \textnormal{variable añadida a } MejorSolucionTemporal) \) \\
            \( MejorRendimientoPunto2 \leftarrow MejorRendimiento \) \\-
    \fin \\

        \( SolucionActual \leftarrow SolucionActual - PeorVariable \) \\
        \( Tabla \leftarrow \fn{agregarFila}(Tabla, MejorSolucionTemporal, \textnormal{tamaño}(MejorSolucionTemporal), MejorRendimiento) \) \\-
    \fin \\

    \( Tabla \leftarrow \fn{ordenarPorRendimiento}(Tabla) \) \\
    \( DataFrame \leftarrow \fn{convertirADataFrame}(Tabla) \) \\

    \devolver \( DataFrame \) \\
  \end{pseudo}
\end{figure}



\section{Resultados}

En esta sección se detallarán tanto los experimentos realizados como los
resultados conseguidos:
\begin{itemize}
  \item Los experimentos realizados, indicando razonadamente la configuración
  empleada, qué se quiere determinar, y como se ha medido.
  \item Los resultados obtenidos en cada experimento, explicando en cada caso lo
  que se ha conseguido.
  \item Análisis de los resultados, haciendo comparativas y obteniendo
  conclusiones.
\end{itemize}

Se pueden hacer uso de tablas, como el ejemplo de la tabla~\ref{tab:ejemplo}.

\begin{table}
  \caption{Ejemplo de tabla}
  \label{tab:ejemplo}
  \centering
  \begin{tabular}{ccc}
    \toprule
    Encabezado 1 & Encabezado 2 & Encabezado 3 \\
    \midrule
    Celda 1 & Celda 2 & Celda 3 \\
    Celda 4 & Celda 5 & Celda 6 \\
    \bottomrule
  \end{tabular}
\end{table}

\section{Conclusiones}

En esta sección se hace un resumen de los resultados obtenidos y se sacan
conclusiones finales.

Además, es importante mencionar las limitaciones del trabajo realizado y
las posibles líneas futuras de investigación.

\section*{Agradecimientos}

Agradecimientos (si los hay).

\begin{thebibliography}{00}
  \bibitem{b1} Primer artículo.
  \bibitem{b2} Segundo artículo.
  \bibitem{b3} Tercer artículo.
\end{thebibliography}

\end{document}
