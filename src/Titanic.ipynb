{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de características para mejorar modelos predictivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuadernillo se realiza el tratamiento de datos del csv TITANIC, así como la implementación y comparación de varios algoritmos de búsqueda y entrenamiento.\n",
    "\n",
    "### Tratamiento de datos\n",
    "\n",
    "Se aplicaron los siguientes procesos de preprocesamiento de datos:\n",
    "\n",
    "    •Normalización de variables predictoras: Se normalizaron las variables Age y Fare utilizando el escalador MinMaxScaler para asegurar que todas las características estén en la misma escala.\n",
    "\n",
    "    •Codificación numérica de atributos discretos: Los atributos Sex, Embarked, Alone y Deck, que originalmente se presentaban como cadenas de texto, fueron codificados numéricamente utilizando las técnicas de OrdinalEncoder o LabelEncoder, según corresponda.\n",
    "\n",
    "### Primer experimento para evaluar la capacidad predictiva del conjunto de variables completo\n",
    "\n",
    "    Para evaluar la calidad de las soluciones que se obtienen con los algoritmos de búsqueda de variables, se realizó un primer experimento en el que se entrenó un modelo de clasificación utilizando todas las variables predictoras disponibles. Se utilizó un árbol de decisión de clasificación.\n",
    "\n",
    "### Algoritmos de búsqueda implementados\n",
    "\n",
    "    •Búsqueda secuencial hacia atrás (backward_sequential_search): Este algoritmo busca encontrar el mejor subconjunto de variables predictoras eliminando iterativamente la variable que más afecta el rendimiento del modelo.\n",
    "\n",
    "    •Búsqueda secuencial hacia atrás mixta (backward_sequential_search_mixto): Similar al anterior, pero también considera añadir variables si se mejora el rendimiento del modelo.\n",
    "\n",
    "### Algoritmos de entrenamiento\n",
    "\n",
    "    •Árboles de decisión de clasificación (DecisionTreeClassifier): Un algoritmo de aprendizaje supervisado utilizado para clasificación.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de atributos detectados discretos: 13\n",
      "\n",
      "Nombres de los atributos detectados discretos:\n",
      "['Initial' 'SibSp' 'Deck' 'Fare_cat' 'Title' 'Sex' 'Is_Married' 'Pclass'\n",
      " 'Parch' 'Embarked' 'Age_band' 'Family_Size' 'Alone']\n",
      "\n",
      "Categorías detectadas de cada atributo:\n",
      "Initial: [0 1 2 3 4]\n",
      "SibSp: [0 1 2 3 4 5 8]\n",
      "Deck: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T' 'U']\n",
      "Fare_cat: [0 1 2 3]\n",
      "Title: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Sex: ['female' 'male']\n",
      "Is_Married: [0 1]\n",
      "Pclass: [1 2 3]\n",
      "Parch: [0 1 2 3 4 5 6]\n",
      "Embarked: ['C' 'Q' 'S']\n",
      "Age_band: [0 1 2 3 4]\n",
      "Family_Size: [ 0  1  2  3  4  5  6  7 10]\n",
      "Alone: ['No' 'Yes']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Initial</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Fare_cat</th>\n",
       "      <th>Title</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Is_Married</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_band</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Initial     SibSp  Deck  Fare_cat   Title  Sex  Is_Married  Pclass  Parch  \\\n",
       "0     0.00  0.166667  1.00  0.000000  0.6875  1.0         0.0     1.0    0.0   \n",
       "1     0.25  0.166667  0.25  1.000000  0.7500  0.0         1.0     0.0    0.0   \n",
       "2     0.50  0.000000  1.00  0.333333  0.5000  0.0         0.0     1.0    0.0   \n",
       "3     0.25  0.166667  0.25  1.000000  0.7500  0.0         1.0     0.0    0.0   \n",
       "4     0.00  0.000000  1.00  0.333333  0.6875  1.0         0.0     1.0    0.0   \n",
       "\n",
       "   Embarked  Age_band  Family_Size  Alone       Age      Fare  Survived  \n",
       "0       1.0      0.25        0.125    0.0  0.271174  0.014151         0  \n",
       "1       0.0      0.50        0.125    0.0  0.472229  0.139136         1  \n",
       "2       1.0      0.25        0.000    1.0  0.321438  0.015469         1  \n",
       "3       1.0      0.50        0.125    0.0  0.434531  0.103644         1  \n",
       "4       1.0      0.50        0.000    1.0  0.434531  0.015713         0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "titanic.head()\n",
    "\n",
    "atributos_discretos = ['Initial', 'SibSp', 'Deck', 'Fare_cat', 'Title', 'Sex', 'Is_Married','Pclass', 'Parch', 'Embarked', \n",
    "                       'Age_band', 'Family_Size', 'Alone']\n",
    "atributos_continuos = ['Age', 'Fare']\n",
    "atributos = titanic.loc[:, atributos_discretos + atributos_continuos]\n",
    "\n",
    "objetivo = titanic['Survived']\n",
    "objetivo.head()  # objetivo es una Series unidimensional\n",
    "\n",
    "\n",
    "codificador_atributos_discretos = OrdinalEncoder()\n",
    "codificador_atributos_discretos.fit(atributos[atributos_discretos])\n",
    "\n",
    "print('Número de atributos detectados discretos:',\n",
    "      f'{codificador_atributos_discretos.n_features_in_}')\n",
    "print()\n",
    "print('Nombres de los atributos detectados discretos:')\n",
    "print(f'{codificador_atributos_discretos.feature_names_in_}')\n",
    "print()\n",
    "print('Categorías detectadas de cada atributo:')\n",
    "for atributo, categorías in zip(\n",
    "    codificador_atributos_discretos.feature_names_in_,\n",
    "    codificador_atributos_discretos.categories_):\n",
    "    print(f'{atributo}: {categorías}')\n",
    "\n",
    "atributos[atributos_discretos] = codificador_atributos_discretos.transform(atributos[atributos_discretos])\n",
    "atributos.head()\n",
    "\n",
    "\n",
    "# El método fit_transform ajusta el codificador a los datos y, a continuación, codifica estos adecuadamente. \n",
    "\n",
    "normalizador = MinMaxScaler(\n",
    "    # Cada atributo se normaliza al intervalo [0, 1]\n",
    "    feature_range=(0, 1)\n",
    ")\n",
    "\n",
    "# Como nos interesa conservar los atributos originales, realizamos la\n",
    "# normalización sobre una copia del DataFrame de atributos\n",
    "atributos_normalizados = atributos.copy()\n",
    "atributos_normalizados[:] = normalizador.fit_transform(atributos_normalizados)\n",
    "atributos_normalizados.head()\n",
    "\n",
    "titanic = atributos_normalizados.copy()\n",
    "titanic['Survived'] = objetivo\n",
    "titanic.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = train_test_split(\n",
    "        # Conjuntos de datos a dividir, usando los mismos índices para ambos\n",
    "        atributos, objetivo,\n",
    "        # Tamaño del conjunto de prueba (20 % en este caso)\n",
    "        test_size=.2,\n",
    "        # Estratificación según la distribución de clases en el atributo objetivo\n",
    "        stratify=objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión de clasificación(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de max_depth: 6\n",
      "Mejor valor de min_samples_split: 15\n",
      "Mejor score: 0.804336415092229\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clasificador_CART = DecisionTreeClassifier(random_state=42)\n",
    "rejilla_de_hiperparámetros = {\n",
    "    # Máxima profundidad del árbol: 3, 4, 5, 6, 7, 8, 9, 10\n",
    "    'max_depth': range(3, 11),\n",
    "    # Mínimo número de ejemplos para poder particionar: 5, 10, 15\n",
    "    'min_samples_split': range(5, 20, 5)\n",
    "}\n",
    "clasificador_CART.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "búsqueda_en_rejilla = GridSearchCV(clasificador_CART,\n",
    "                                   rejilla_de_hiperparámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "búsqueda_en_rejilla.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "# Obtener los mejores parámetros de la búsqueda en rejilla\n",
    "mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "# Guardar el valor de max_depth en una variable\n",
    "max_depth_mejor = mejores_parametros.get('max_depth')\n",
    "min_samples_split_mejor = mejores_parametros.get('min_samples_split')\n",
    "mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "\n",
    "print(\"Mejor valor de max_depth:\", max_depth_mejor)\n",
    "print(\"Mejor valor de min_samples_split:\", min_samples_split_mejor)\n",
    "print(\"Mejor score:\", mejor_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7764697081557547"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_validación_cruzada = cross_validate(clasificador_CART,\n",
    "                                               atributos_entrenamiento,\n",
    "                                               objetivo_entrenamiento,\n",
    "                                               scoring='balanced_accuracy',\n",
    "                                               cv=10, \n",
    "                                               n_jobs=-1,)\n",
    "#resultados_validación_cruzada\n",
    "resultados_validación_cruzada['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabes predictoras: \n",
      "Index(['Initial', 'SibSp', 'Deck', 'Fare_cat', 'Title', 'Sex', 'Is_Married',\n",
      "       'Pclass', 'Parch', 'Embarked', 'Age_band', 'Family_Size', 'Alone',\n",
      "       'Age', 'Fare'],\n",
      "      dtype='object')\n",
      "\n",
      "Precisión: 0.8595505617977528\n",
      "\n",
      "Valores: Survived\n",
      "0    439\n",
      "1    273\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Matriz de confusión: \n",
      "[[383  56]\n",
      " [ 44 229]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.7971014492753623\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Ajustar el modelo\n",
    "clasificador_CART = DecisionTreeClassifier(max_depth=max_depth_mejor, min_samples_split=min_samples_split_mejor, random_state=42)\n",
    "clasificador_CART.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Calcular la Tasa de acierto del modelo\n",
    "score = clasificador_CART.score(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Obtener las predicciones\n",
    "predicciones = clasificador_CART.predict(atributos_entrenamiento)\n",
    "\n",
    "# Contar los valores de la variable objetivo\n",
    "values = pd.Series(objetivo_entrenamiento).value_counts()\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "m_confusion = confusion_matrix(objetivo_entrenamiento, predicciones)\n",
    "\n",
    "# Calcular la sensibilidad\n",
    "predicciones_prueba = clasificador_CART.predict(atributos_prueba)\n",
    "recallscore = recall_score(objetivo_prueba, predicciones_prueba)\n",
    "\n",
    "print(f'Variabes predictoras: \\n{atributos_entrenamiento.columns}')\n",
    "print()\n",
    "print(f'Tasa de acierto: {score}')\n",
    "print()\n",
    "print(f'Valores: {values}')\n",
    "print()\n",
    "print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "print()\n",
    "print(f'Sensibilidad del conjunto de pruebas: {recallscore}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7971014492753623"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(objetivo_prueba, predicciones_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "normalizador = ColumnTransformer([('normalizador',\n",
    "                                   MinMaxScaler(feature_range=(0, 1)),\n",
    "                                   atributos_discretos + atributos_continuos)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de n_neighbors: 3\n",
      "Mejor valor de mmetric: euclidean\n",
      "Mejor score: 0.8240045806906272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "tubería_kNN = Pipeline([('preprocesador', normalizador),\n",
    "                        ('kNN', KNeighborsClassifier())])\n",
    "rejilla_de_parámetros = {\n",
    "    # Número de vecinos impar (tarea de clasificación binaria)\n",
    "    'kNN__n_neighbors': range(1, 10, 2),\n",
    "    # Considerar las distancias Manhattan y euclídea\n",
    "    'kNN__metric': ['manhattan', 'euclidean']\n",
    "}\n",
    "\n",
    "\n",
    "búsqueda_en_rejilla = GridSearchCV(tubería_kNN,\n",
    "                                   rejilla_de_parámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10)\n",
    "búsqueda_en_rejilla.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Guardar el valor de max_depth en una variable\n",
    "mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "n_neighbors_mejor = mejores_parametros.get('kNN__n_neighbors')\n",
    "metric_mejor = mejores_parametros.get('kNN__metric')\n",
    "mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "print(\"Mejor valor de n_neighbors:\", n_neighbors_mejor)\n",
    "print(\"Mejor valor de mmetric:\", metric_mejor)\n",
    "print(\"Mejor score:\", mejor_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabes predictoras: Index(['Initial', 'SibSp', 'Deck', 'Fare_cat', 'Title', 'Sex', 'Is_Married',\n",
      "       'Pclass', 'Parch', 'Embarked', 'Age_band', 'Family_Size', 'Alone',\n",
      "       'Age', 'Fare'],\n",
      "      dtype='object')\n",
      "Precisión: 0.848314606741573\n",
      "Valores: Survived\n",
      "0    439\n",
      "1    273\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[389  50]\n",
      " [ 58 215]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.5797101449275363\n"
     ]
    }
   ],
   "source": [
    "clasificador_kNN = KNeighborsClassifier(n_neighbors=n_neighbors_mejor, metric=metric_mejor)\n",
    "\n",
    "clasificador_kNN.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "\n",
    "# Calcular la Tasa de acierto del modelo\n",
    "score = clasificador_kNN.score(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Obtener las predicciones\n",
    "predicciones = clasificador_kNN.predict(atributos_entrenamiento)\n",
    "\n",
    "# Contar los valores de la variable objetivo\n",
    "values = pd.Series(objetivo_entrenamiento).value_counts()\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "m_confusion = confusion_matrix(objetivo_entrenamiento, predicciones)\n",
    "\n",
    "# Calcular la sensibilidad\n",
    "predicciones_prueba = clasificador_kNN.predict(atributos_prueba)\n",
    "recallscore = recall_score(objetivo_prueba, predicciones_prueba)\n",
    "\n",
    "print(f'Variabes predictoras: {atributos_entrenamiento.columns}')\n",
    "print(f'Tasa de acierto: {score}')\n",
    "print(f'Valores: {values}')\n",
    "print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "print()\n",
    "print(f'Sensibilidad del conjunto de pruebas: {recallscore}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de búsqueda hacia atrás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esto parametros nos permite tener el minimo num de variables de predictoras y un mayor score\n",
    "import funciones.BusquedaSecuencialAtras as bsa\n",
    "bsatras = bsa.backward_sequential_search(titanic, 'Survived', model, 1, 2)\n",
    "bsatras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión de clasificación(DecisionTreeClassifier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for k in range(0, len(bsatras)-1, 1):\n",
    "    selected_variables = bsatras.iloc[k]['variables']  # Obtiener las variables de la mejor iteración\n",
    "    solucion = titanic.loc[:, selected_variables]\n",
    "    \n",
    "\n",
    "    # Dividir los datos\n",
    "    X = titanic[selected_variables]\n",
    "    objetivo= titanic['Survived']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, objetivo, test_size=.2,stratify=objetivo)\n",
    "\n",
    "    clasificador_CART.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "    búsqueda_en_rejilla = GridSearchCV(clasificador_CART,\n",
    "                                   rejilla_de_hiperparámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "   # Obtener los mejores parámetros de la búsqueda en rejilla\n",
    "    mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "    # Guardar el valor de max_depth en una variable\n",
    "    max_depth_mejor = mejores_parametros.get('max_depth')\n",
    "    min_samples_split_mejor = mejores_parametros.get('min_samples_split')\n",
    "    mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "\n",
    "    print(\"Mejor valor de max_depth:\", max_depth_mejor)\n",
    "    print(\"Mejor valor de min_samples_split:\", min_samples_split_mejor)\n",
    "    print(\"Mejor score:\", mejor_score)\n",
    "\n",
    "\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    clasificador_CART = DecisionTreeClassifier(\n",
    "        max_depth=max_depth_mejor,  # Máxima profundidad del árbol\n",
    "        min_samples_split=min_samples_split_mejor  # Mínimo número de ejemplos para poder particionar\n",
    "    )\n",
    "\n",
    "    resultados_validación_cruzada = cross_validate(clasificador_CART,\n",
    "                                                X_train,\n",
    "                                                y_train,\n",
    "                                                scoring='balanced_accuracy',\n",
    "                                                cv=10)\n",
    "\n",
    "    # Ajustar el modelo\n",
    "    clasificador_CART = DecisionTreeClassifier(max_depth=max_depth_mejor)\n",
    "    clasificador_CART.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la Tasa de acierto del modelo\n",
    "    score = clasificador_CART.score(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones\n",
    "    predicciones = clasificador_CART.predict(X_train)\n",
    "\n",
    "    # Contar los valores de la variable objetivo\n",
    "    values = pd.Series(y_train).value_counts()\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    m_confusion = confusion_matrix(y_train, predicciones)\n",
    "\n",
    "    # Calcular la sensibilidad\n",
    "    predicciones_prueba = clasificador_CART.predict(X_test)\n",
    "    recallscore = recall_score(objetivo_prueba, predicciones_prueba)\n",
    "\n",
    "    print(f'Variabes predictoras: \\n{selected_variables}')\n",
    "    print(f'Tasa de acierto: {score}')\n",
    "    print(f'Valores: {values}')\n",
    "    print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "    print()\n",
    "    print(f'Sensibilidad del conjunto de pruebas: {recallscore}')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "for k in range(0, len(bsatras)-1, 1):\n",
    "\n",
    "    selected_variables = bsatras.iloc[k]['variables']  # Obtiener las variables de la mejor iteración\n",
    "    X = titanic.loc[:, selected_variables]\n",
    "    clasificador_kNN.fit(solucion, objetivo)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, objetivo, test_size=.2,stratify=objetivo)\n",
    "    \n",
    "    búsqueda_en_rejilla = GridSearchCV(clasificador_kNN,\n",
    "                                   rejilla_de_hiperparámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "   # Obtener los mejores parámetros de la búsqueda en rejilla\n",
    "    mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "    n_neighbors_mejor = mejores_parametros.get('kNN__n_neighbors')\n",
    "    metric_mejor = mejores_parametros.get('kNN__metric')\n",
    "    mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "    print(\"Mejor valor de n_neighbors:\", n_neighbors_mejor)\n",
    "    print(\"Mejor valor de mmetric:\", metric_mejor)\n",
    "    print(\"Mejor score:\", mejor_score)\n",
    "\n",
    "    clasificador_kNN = KNeighborsClassifier(\n",
    "        # Para cada ejemplo se consideran los 5 ejemplos más cercanos\n",
    "        n_neighbors=n_neighbors_mejor,\n",
    "        # La cercanía viene determinada por la distancia euclídea\n",
    "        metric=metric_mejor\n",
    "    )\n",
    "\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    clasificador_kNN.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la tasa de acierto del modelo\n",
    "    score = clasificador_kNN.score(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones\n",
    "    predicciones = clasificador_kNN.predict(X_train)\n",
    "\n",
    "    # Contar los valores de la variable objetivo\n",
    "    values = pd.Series(y_train).value_counts()\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    m_confusion = confusion_matrix(y_train, predicciones)\n",
    "\n",
    "    # Calcular la sensibilidad\n",
    "    predicciones_prueba = clasificador_kNN.predict(X_train)\n",
    "    recallscore = recall_score(y_train, predicciones_prueba)\n",
    "\n",
    "    print(f'Variabes predictoras: {selected_variables}')\n",
    "    print(f'Tasa de acierto: {score}')\n",
    "    print(f'Valores: {values}')\n",
    "    print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "    print()\n",
    "    print(f'Sensibilidad del conjunto de pruebas: {recallscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de búsqueda hacia atrás mixta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funciones.BusquedaSecuencialAtrasMixta as bsam\n",
    "busq_atras_mixta = bsam.backward_sequential_mixed_search(titanic, 'Survived', model, 10, 6, 10)\n",
    "busq_atras_mixta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión de clasificación(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for k in range(0, len(busq_atras_mixta)-1, 1):\n",
    "    selected_variables = busq_atras_mixta.iloc[k]['variables']  # Obtiener las variables de la mejor iteración\n",
    "    solucion = titanic.loc[:, selected_variables]\n",
    "    # Realizar la búsqueda secuencial hacia atrás\n",
    "    model = DecisionTreeClassifier(max_depth=max_depth_mejor)\n",
    "\n",
    "    # Dividir los datos\n",
    "    X = titanic[selected_variables]\n",
    "    objetivo= titanic['Survived']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, objetivo, test_size=.2,stratify=objetivo)\n",
    "\n",
    "    búsqueda_en_rejilla = GridSearchCV(clasificador_CART,\n",
    "                                   rejilla_de_hiperparámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "   # Obtener los mejores parámetros de la búsqueda en rejilla\n",
    "    mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "    # Guardar el valor de max_depth en una variable\n",
    "    max_depth_mejor = mejores_parametros.get('max_depth')\n",
    "    min_samples_split_mejor = mejores_parametros.get('min_samples_split')\n",
    "    mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "    print(\"Mejor valor de max_depth:\", max_depth_mejor)\n",
    "    print(\"Mejor valor de min_samples_split:\", min_samples_split_mejor)\n",
    "    print(\"Mejor score:\", mejor_score)\n",
    "\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    clasificador_CART = DecisionTreeClassifier(\n",
    "        max_depth=max_depth_mejor,  # Máxima profundidad del árbol\n",
    "        min_samples_split=min_samples_split_mejor  # Mínimo número de ejemplos para poder particionar\n",
    "    )\n",
    "\n",
    "    resultados_validación_cruzada = cross_validate(clasificador_CART,\n",
    "                                                X_train,\n",
    "                                                y_train,\n",
    "                                                scoring='balanced_accuracy',\n",
    "                                                cv=10)\n",
    "\n",
    "    # Ajustar el modelo\n",
    "    clasificador_CART = DecisionTreeClassifier(max_depth=max_depth_mejor)\n",
    "    clasificador_CART.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la Tasa de acierto del modelo\n",
    "    score = clasificador_CART.score(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones\n",
    "    predicciones = clasificador_CART.predict(X_train)\n",
    "\n",
    "    # Contar los valores de la variable objetivo\n",
    "    values = pd.Series(y_train).value_counts()\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    m_confusion = confusion_matrix(y_train, predicciones)\n",
    "\n",
    "    # Calcular la sensibilidad\n",
    "    predicciones_prueba = clasificador_CART.predict(X_test)\n",
    "    recallscore = recall_score(y_test, predicciones_prueba)\n",
    "\n",
    "    # Imprimir los resultados\n",
    "    print(f'Variabes predictoras: \\n{selected_variables}')\n",
    "    print(f'Tasa de acierto: {score}')\n",
    "    print(f'Valores: {values}')\n",
    "    print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "    print()  \n",
    "    print(f'Sensibilidad del conjunto de pruebas: {recallscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "clasificador_kNN = KNeighborsClassifier(\n",
    "    # Para cada ejemplo se consideran los 5 ejemplos más cercanos\n",
    "    n_neighbors=5,\n",
    "    # La cercanía viene determinada por la distancia euclídea\n",
    "    metric='manhattan'\n",
    ")\n",
    "clasificador_kNN.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "for k in range(0, len(busq_atras_mixta)-1, 1):\n",
    "\n",
    "    selected_variables = busq_atras_mixta.iloc[k]['variables']  # Obtiener las variables de la mejor iteración\n",
    "    solucion = titanic.loc[:, selected_variables]\n",
    "    clasificador_kNN.fit(solucion, objetivo)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, objetivo, test_size=.2,stratify=objetivo)\n",
    "\n",
    "    búsqueda_en_rejilla = GridSearchCV(clasificador_kNN,\n",
    "                                   rejilla_de_hiperparámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "   # Obtener los mejores parámetros de la búsqueda en rejilla\n",
    "    mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "    # Guardar el valor de max_depth en una variable\n",
    "    mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "    n_neighbors_mejor = mejores_parametros.get('kNN__n_neighbors')\n",
    "    metric_mejor = mejores_parametros.get('kNN__metric')\n",
    "    mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "    print(\"Mejor valor de n_neighbors:\", n_neighbors_mejor)\n",
    "    print(\"Mejor valor de mmetric:\", metric_mejor)\n",
    "    print(\"Mejor score:\", mejor_score)\n",
    "\n",
    "    clasificador_kNN = KNeighborsClassifier(\n",
    "    # Para cada ejemplo se consideran los 5 ejemplos más cercanos\n",
    "    n_neighbors=n_neighbors_mejor,\n",
    "    # La cercanía viene determinada por la distancia euclídea\n",
    "    metric=metric_mejor\n",
    ")\n",
    "\n",
    "   # Entrenar el modelo\n",
    "    clasificador_kNN.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la Tasa de acierto del modelo\n",
    "    score = clasificador_kNN.score(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones\n",
    "    predicciones = clasificador_kNN.predict(X_train)\n",
    "\n",
    "    # Contar los valores de la variable objetivo\n",
    "    values = pd.Series(y_train).value_counts()\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    m_confusion = confusion_matrix(y_train, predicciones)\n",
    "\n",
    "    # Calcular la sensibilidad\n",
    "    predicciones_prueba = clasificador_kNN.predict(X_train)\n",
    "    recallscore = recall_score(y_train, predicciones_prueba)\n",
    "\n",
    "    print(f'Variabes predictoras: {selected_variables}')\n",
    "    print(f'Tasa de acierto: {score}')\n",
    "    print(f'Valores: {values}')\n",
    "    print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "    print()\n",
    "    print(f'Sensibilidad del conjunto de pruebas: {recallscore}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
