{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de características para mejorar modelos predictivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuadernillo se realiza el tratamiento de datos del csv TITANIC, así como la implementación y comparación de varios algoritmos de búsqueda y entrenamiento.\n",
    "\n",
    "### Tratamiento de datos\n",
    "\n",
    "Se aplicaron los siguientes procesos de preprocesamiento de datos:\n",
    "\n",
    "    •Normalización de variables predictoras: Se normalizaron las variables Age y Fare utilizando el escalador MinMaxScaler para asegurar que todas las características estén en la misma escala.\n",
    "\n",
    "    •Codificación numérica de atributos discretos: Los atributos Sex, Embarked, Alone y Deck, que originalmente se presentaban como cadenas de texto, fueron codificados numéricamente utilizando las técnicas de OrdinalEncoder o LabelEncoder, según corresponda.\n",
    "\n",
    "### Primer experimento para evaluar la capacidad predictiva del conjunto de variables completo\n",
    "\n",
    "    Para evaluar la calidad de las soluciones que se obtienen con los algoritmos de búsqueda de variables, se realizó un primer experimento en el que se entrenó un modelo de clasificación utilizando todas las variables predictoras disponibles. Se utilizó un árbol de decisión de clasificación.\n",
    "\n",
    "### Algoritmos de búsqueda implementados\n",
    "\n",
    "    •Búsqueda secuencial hacia atrás (backward_sequential_search): Este algoritmo busca encontrar el mejor subconjunto de variables predictoras eliminando iterativamente la variable que más afecta el rendimiento del modelo.\n",
    "\n",
    "    •Búsqueda secuencial hacia atrás mixta (backward_sequential_search_mixto): Similar al anterior, pero también considera añadir variables si se mejora el rendimiento del modelo.\n",
    "\n",
    "### Algoritmos de entrenamiento\n",
    "\n",
    "    •Árboles de decisión de clasificación (DecisionTreeClassifier): Un algoritmo de aprendizaje supervisado utilizado para clasificación.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.521037</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.545989</td>\n",
       "      <td>0.363733</td>\n",
       "      <td>0.593753</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703140</td>\n",
       "      <td>0.731113</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>0.605518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.668310</td>\n",
       "      <td>0.450698</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643144</td>\n",
       "      <td>0.272574</td>\n",
       "      <td>0.615783</td>\n",
       "      <td>0.501591</td>\n",
       "      <td>0.289880</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203608</td>\n",
       "      <td>0.348757</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>0.141323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.539818</td>\n",
       "      <td>0.435214</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.601496</td>\n",
       "      <td>0.390260</td>\n",
       "      <td>0.595743</td>\n",
       "      <td>0.449417</td>\n",
       "      <td>0.514309</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462512</td>\n",
       "      <td>0.635686</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.211247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.508442</td>\n",
       "      <td>0.374508</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.210090</td>\n",
       "      <td>0.360839</td>\n",
       "      <td>0.233501</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.565604</td>\n",
       "      <td>0.522863</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.241347</td>\n",
       "      <td>0.094008</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.629893</td>\n",
       "      <td>0.156578</td>\n",
       "      <td>0.630986</td>\n",
       "      <td>0.489290</td>\n",
       "      <td>0.430351</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.463918</td>\n",
       "      <td>0.518390</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>0.186816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.506948</td>\n",
       "      <td>0.341575</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0     0.521037      0.022658        0.545989   0.363733         0.593753   \n",
       "1     0.643144      0.272574        0.615783   0.501591         0.289880   \n",
       "2     0.601496      0.390260        0.595743   0.449417         0.514309   \n",
       "3     0.210090      0.360839        0.233501   0.102906         0.811321   \n",
       "4     0.629893      0.156578        0.630986   0.489290         0.430351   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0          0.792037        0.703140             0.731113       0.686364   \n",
       "1          0.181768        0.203608             0.348757       0.379798   \n",
       "2          0.431017        0.462512             0.635686       0.509596   \n",
       "3          0.811361        0.565604             0.522863       0.776263   \n",
       "4          0.347893        0.463918             0.518390       0.378283   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                0.605518  ...       0.141525         0.668310    0.450698   \n",
       "1                0.141323  ...       0.303571         0.539818    0.435214   \n",
       "2                0.211247  ...       0.360075         0.508442    0.374508   \n",
       "3                1.000000  ...       0.385928         0.241347    0.094008   \n",
       "4                0.186816  ...       0.123934         0.506948    0.341575   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          0.601136           0.619292         0.568610              0.912027   \n",
       "1          0.347553           0.154563         0.192971              0.639175   \n",
       "2          0.483590           0.385375         0.359744              0.835052   \n",
       "3          0.915472           0.814012         0.548642              0.884880   \n",
       "4          0.437364           0.172415         0.319489              0.558419   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  Diagnosis  \n",
       "0        0.598462                 0.418864          0  \n",
       "1        0.233590                 0.222878          0  \n",
       "2        0.403706                 0.213433          0  \n",
       "3        1.000000                 0.773711          0  \n",
       "4        0.157500                 0.142595          0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "breast_cancer = pd.read_csv('../data/BreastCancer.csv')\n",
    "breast_cancer.head()\n",
    "\n",
    "atributos_continuos = ['mean radius' ,'mean texture' ,'mean perimeter' ,'mean area' ,'mean smoothness' ,'mean compactness' ,'mean concavity' ,\n",
    "                       'mean concave points' ,'mean symmetry' ,'mean fractal dimension' ,'radius error' ,'texture error' ,'perimeter error' ,\n",
    "                       'area error' ,'smoothness error' ,'compactness error' ,'concavity error' ,'concave points error','symmetry error','fractal dimension error',\n",
    "                       'worst radius' ,'worst texture' ,'worst perimeter','worst area' ,'worst smoothness','worst compactness' ,'worst concavity' ,'worst concave points','worst symmetry','worst fractal dimension']\n",
    "atributos = breast_cancer.loc[:, atributos_continuos]\n",
    "\n",
    "objetivo = breast_cancer['diagnosis']\n",
    "objetivo.head()  # objetivo es una Series unidimensional\n",
    "\n",
    "normalizador = MinMaxScaler(\n",
    "    # Cada atributo se normaliza al intervalo [0, 1]\n",
    "    feature_range=(0, 1)\n",
    ")\n",
    "\n",
    "# Como nos interesa conservar los atributos originales, realizamos la\n",
    "# normalización sobre una copia del DataFrame de atributos\n",
    "atributos_normalizados = atributos.copy()\n",
    "atributos_normalizados[:] = normalizador.fit_transform(atributos_normalizados)\n",
    "atributos_normalizados.head()\n",
    "\n",
    "breast_cancer = atributos_normalizados.copy()\n",
    "breast_cancer['Diagnosis'] = objetivo\n",
    "breast_cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = train_test_split(\n",
    "        # Conjuntos de datos a dividir, usando los mismos índices para ambos\n",
    "        atributos, objetivo,\n",
    "        # Tamaño del conjunto de prueba (20 % en este caso)\n",
    "        test_size=.2,\n",
    "        # Estratificación según la distribución de clases en el atributo objetivo\n",
    "        stratify=objetivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión de clasificación(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de max_depth: 3\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.93366777745581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clasificador_CART = DecisionTreeClassifier(random_state=42)\n",
    "rejilla_de_hiperparámetros = {\n",
    "    # Máxima profundidad del árbol: 3, 4, 5, 6, 7, 8, 9, 10\n",
    "    'max_depth': range(3, 11),\n",
    "    # Mínimo número de ejemplos para poder particionar: 5, 10, 15\n",
    "    'min_samples_split': range(5, 20, 5)\n",
    "}\n",
    "clasificador_CART.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "búsqueda_en_rejilla = GridSearchCV(clasificador_CART,\n",
    "                                   rejilla_de_hiperparámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "búsqueda_en_rejilla.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Obtener los mejores parámetros de la búsqueda en rejilla\n",
    "mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "# Guardar el valor de max_depth en una variable\n",
    "max_depth_mejor = mejores_parametros.get('max_depth')\n",
    "min_samples_split_mejor = mejores_parametros.get('min_samples_split')\n",
    "mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "print(\"Mejor valor de max_depth:\", max_depth_mejor)\n",
    "print(\"Mejor valor de min_samples_split:\", min_samples_split_mejor)\n",
    "print(\"Mejor score:\", mejor_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9150246305418719"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados_validación_cruzada = cross_validate(clasificador_CART,\n",
    "                                               atributos_entrenamiento,\n",
    "                                               objetivo_entrenamiento,\n",
    "                                               scoring='balanced_accuracy',\n",
    "                                               cv=10, \n",
    "                                               n_jobs=-1,)\n",
    "#resultados_validación_cruzada\n",
    "resultados_validación_cruzada['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabes predictoras: \n",
      "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
      "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
      "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
      "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
      "      dtype='object')\n",
      "\n",
      "Tasa de acierto: 0.9714285714285714\n",
      "\n",
      "Valores: diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  4 281]]\n",
      "\n",
      "Sensiilidad: 0.9305555555555556\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Supongamos que atributos es un DataFrame con las características y objetivo es una Serie con la variable objetivo\n",
    "# Ajustar el modelo\n",
    "clasificador_CART = DecisionTreeClassifier(max_depth=max_depth_mejor, min_samples_split=min_samples_split_mejor, random_state=42)\n",
    "clasificador_CART.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Calcular la Tasa de acierto del modelo\n",
    "score = clasificador_CART.score(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Obtener las predicciones\n",
    "predicciones = clasificador_CART.predict(atributos_entrenamiento)\n",
    "\n",
    "# Contar los valores de la variable objetivo\n",
    "values = pd.Series(objetivo_entrenamiento).value_counts()\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "m_confusion = confusion_matrix(objetivo_entrenamiento, predicciones)\n",
    "\n",
    "# Calcular la sensibilidad\n",
    "predicciones_prueba = clasificador_CART.predict(atributos_prueba)\n",
    "recallscore = recall_score(objetivo_prueba, predicciones_prueba)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f'Variabes predictoras: \\n{atributos_entrenamiento.columns}')\n",
    "print()\n",
    "print(f'Tasa de acierto: {score}')\n",
    "print()\n",
    "print(f'Valores: {values}')\n",
    "print()\n",
    "print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "print()\n",
    "print(f'Sensiilidad: {recallscore}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "normalizador = ColumnTransformer([('normalizador',\n",
    "                                   MinMaxScaler(feature_range=(0, 1)),\n",
    "                                   atributos_continuos)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de n_neighbors: 5\n",
      "Mejor valor de mmetric: manhattan\n",
      "Mejor score: 0.9646624166908143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "tubería_kNN = Pipeline([('preprocesador', normalizador),\n",
    "                        ('kNN', KNeighborsClassifier())])\n",
    "rejilla_de_parámetros = {\n",
    "    # Número de vecinos impar (tarea de clasificación binaria)\n",
    "    'kNN__n_neighbors': range(1, 10, 2),\n",
    "    # Considerar las distancias Manhattan y euclídea\n",
    "    'kNN__metric': ['manhattan', 'euclidean']\n",
    "}\n",
    "\n",
    "\n",
    "búsqueda_en_rejilla = GridSearchCV(tubería_kNN,\n",
    "                                   rejilla_de_parámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)\n",
    "búsqueda_en_rejilla.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Guardar el valor de max_depth en una variable\n",
    "mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "n_neighbors_mejor = mejores_parametros.get('kNN__n_neighbors')\n",
    "metric_mejor = mejores_parametros.get('kNN__metric')\n",
    "mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "print(\"Mejor valor de n_neighbors:\", n_neighbors_mejor)\n",
    "print(\"Mejor valor de mmetric:\", metric_mejor)\n",
    "print(\"Mejor score:\", mejor_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabes predictoras: Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
      "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
      "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
      "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
      "       'smoothness error', 'compactness error', 'concavity error',\n",
      "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
      "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
      "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
      "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
      "      dtype='object')\n",
      "Tasa de acierto: 0.9582417582417583\n",
      "Valores: diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[156  14]\n",
      " [  5 280]]\n",
      "\n",
      "Sensiilidad: 0.9305555555555556\n"
     ]
    }
   ],
   "source": [
    "clasificador_kNN = KNeighborsClassifier(n_neighbors=n_neighbors_mejor, metric=metric_mejor)\n",
    "\n",
    "clasificador_kNN.fit(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "\n",
    "# Calcular la Tasa de acierto del modelo\n",
    "score = clasificador_kNN.score(atributos_entrenamiento, objetivo_entrenamiento)\n",
    "\n",
    "# Obtener las predicciones\n",
    "predicciones = clasificador_kNN.predict(atributos_entrenamiento)\n",
    "\n",
    "# Contar los valores de la variable objetivo\n",
    "values = pd.Series(objetivo_entrenamiento).value_counts()\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "m_confusion = confusion_matrix(objetivo_entrenamiento, predicciones)\n",
    "\n",
    "# Calcular la sensibilidad\n",
    "predicciones_prueba = clasificador_kNN.predict(atributos_prueba)\n",
    "recallscore = recall_score(objetivo_prueba, predicciones_prueba)\n",
    "\n",
    "print(f'Variabes predictoras: {atributos_entrenamiento.columns}')\n",
    "print(f'Tasa de acierto: {score}')\n",
    "print(f'Valores: {values}')\n",
    "print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "print()\n",
    "print(f'Sensiilidad: {recallscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de búsqueda hacia atrás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>size</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>13</td>\n",
       "      <td>0.973639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.973105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.972830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.972728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.972450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>14</td>\n",
       "      <td>0.972439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.972415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.972322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[mean texture, mean area, mean concave points,...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.972108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[mean texture, mean area, mean smoothness, mea...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.971922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[mean texture, mean concave points, area error...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.971448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[mean texture, mean area, mean smoothness, mea...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.971168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[mean texture, mean area, mean smoothness, mea...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.970595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[mean texture, mean concave points, area error...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.970355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[mean texture, mean area, mean smoothness, mea...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.969788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[mean texture, mean area, mean smoothness, mea...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.969442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[mean texture, mean concave points, worst text...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.968272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mean texture, mean concave points, worst text...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.967955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[mean texture, mean area, mean smoothness, mea...</td>\n",
       "      <td>24</td>\n",
       "      <td>0.967661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[mean texture, mean area, mean smoothness, mea...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.967634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mean concave points, worst texture, worst are...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.966308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[mean radius, mean texture, mean area, mean sm...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.966102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.965971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>27</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.962138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mean concave points, worst texture, worst area]</td>\n",
       "      <td>3</td>\n",
       "      <td>0.961502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>29</td>\n",
       "      <td>0.960911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[mean radius, mean texture, mean perimeter, me...</td>\n",
       "      <td>30</td>\n",
       "      <td>0.957078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mean concave points, worst area]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.921849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[worst area]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.871433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            variables  size     score\n",
       "12  [mean texture, mean area, mean concave points,...    13  0.973639\n",
       "10  [mean texture, mean area, mean concave points,...    11  0.973105\n",
       "11  [mean texture, mean area, mean concave points,...    12  0.972830\n",
       "15  [mean texture, mean area, mean concave points,...    16  0.972728\n",
       "14  [mean texture, mean area, mean concave points,...    15  0.972450\n",
       "13  [mean texture, mean area, mean concave points,...    14  0.972439\n",
       "9   [mean texture, mean area, mean concave points,...    10  0.972415\n",
       "8   [mean texture, mean area, mean concave points,...     9  0.972322\n",
       "16  [mean texture, mean area, mean concave points,...    17  0.972108\n",
       "17  [mean texture, mean area, mean smoothness, mea...    18  0.971922\n",
       "7   [mean texture, mean concave points, area error...     8  0.971448\n",
       "18  [mean texture, mean area, mean smoothness, mea...    19  0.971168\n",
       "21  [mean texture, mean area, mean smoothness, mea...    22  0.970595\n",
       "6   [mean texture, mean concave points, area error...     7  0.970355\n",
       "19  [mean texture, mean area, mean smoothness, mea...    20  0.969788\n",
       "20  [mean texture, mean area, mean smoothness, mea...    21  0.969442\n",
       "5   [mean texture, mean concave points, worst text...     6  0.968272\n",
       "4   [mean texture, mean concave points, worst text...     5  0.967955\n",
       "23  [mean texture, mean area, mean smoothness, mea...    24  0.967661\n",
       "22  [mean texture, mean area, mean smoothness, mea...    23  0.967634\n",
       "3   [mean concave points, worst texture, worst are...     4  0.966308\n",
       "24  [mean radius, mean texture, mean area, mean sm...    25  0.966102\n",
       "25  [mean radius, mean texture, mean perimeter, me...    26  0.965971\n",
       "26  [mean radius, mean texture, mean perimeter, me...    27  0.964450\n",
       "27  [mean radius, mean texture, mean perimeter, me...    28  0.962138\n",
       "2    [mean concave points, worst texture, worst area]     3  0.961502\n",
       "29  [mean radius, mean texture, mean perimeter, me...    29  0.960911\n",
       "28  [mean radius, mean texture, mean perimeter, me...    30  0.957078\n",
       "1                   [mean concave points, worst area]     2  0.921849\n",
       "0                                        [worst area]     1  0.871433"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Esto parametros nos permite tener el minimo num de variables de predictoras y un mayor score\n",
    "import funciones.BusquedaSecuencialAtras as bsa\n",
    "bsatras = bsa.backward_sequential_search(breast_cancer, 'Diagnosis', model, 10, 6)\n",
    "bsatras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión de clasificación(DecisionTreeClassifier)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de max_depth: 8\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9226745870762099\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9824175824175824\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[166   4]\n",
      " [  4 281]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9583333333333334\n",
      "Mejor valor de max_depth: 4\n",
      "Mejor valor de min_samples_split: 15\n",
      "Mejor score: 0.9341314111851636\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9824175824175824\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  2 283]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9861111111111112\n",
      "Mejor valor de max_depth: 9\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9520066647348594\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'mean fractal dimension', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9802197802197802\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[165   5]\n",
      " [  4 281]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9027777777777778\n",
      "Mejor valor de max_depth: 7\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9254310344827588\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'compactness error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9846153846153847\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[163   7]\n",
      " [  0 285]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9027777777777778\n",
      "Mejor valor de max_depth: 10\n",
      "Mejor valor de min_samples_split: 15\n",
      "Mejor score: 0.9413358446827008\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'compactness error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9912087912087912\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[167   3]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9444444444444444\n",
      "Mejor valor de max_depth: 4\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9406874818893074\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.989010989010989\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[165   5]\n",
      " [  0 285]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9305555555555556\n",
      "Mejor valor de max_depth: 5\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9446175021732831\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points']\n",
      "Tasa de acierto: 0.9824175824175824\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[168   2]\n",
      " [  6 279]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9861111111111112\n",
      "Mejor valor de max_depth: 7\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9325304259634889\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'area error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9305555555555556\n",
      "Mejor valor de max_depth: 6\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9289589973920602\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9824175824175824\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[163   7]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9861111111111112\n",
      "Mejor valor de max_depth: 5\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9395501303969862\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean smoothness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9846153846153847\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9861111111111112\n",
      "Mejor valor de max_depth: 5\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9424913068675748\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean concave points', 'area error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points']\n",
      "Tasa de acierto: 0.9802197802197802\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[165   5]\n",
      " [  4 281]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9027777777777778\n",
      "Mejor valor de max_depth: 10\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9337474645030426\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean smoothness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9824175824175824\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  0 285]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9583333333333334\n",
      "Mejor valor de max_depth: 5\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9371957403651117\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9868131868131869\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[165   5]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9861111111111112\n",
      "Mejor valor de max_depth: 6\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9390430310055058\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean concave points', 'area error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity']\n",
      "Tasa de acierto: 0.9802197802197802\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9861111111111112\n",
      "Mejor valor de max_depth: 10\n",
      "Mejor valor de min_samples_split: 10\n",
      "Mejor score: 0.9178426543031005\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean smoothness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9736263736263736\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[166   4]\n",
      " [  8 277]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9444444444444444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de max_depth: 10\n",
      "Mejor valor de min_samples_split: 15\n",
      "Mejor score: 0.9254926108374384\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9868131868131869\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[168   2]\n",
      " [  4 281]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9027777777777778\n",
      "Mejor valor de max_depth: 3\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9599971022891914\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean concave points', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity']\n",
      "Tasa de acierto: 0.9846153846153847\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[166   4]\n",
      " [  3 282]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9305555555555556\n",
      "Mejor valor de max_depth: 9\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9376412634019126\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean concave points', 'worst texture', 'worst area', 'worst smoothness']\n",
      "Tasa de acierto: 0.9846153846153847\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[165   5]\n",
      " [  2 283]]\n",
      "\n",
      "\n",
      "Sensiilidad: 1.0\n",
      "Mejor valor de max_depth: 8\n",
      "Mejor valor de min_samples_split: 15\n",
      "Mejor score: 0.9367321066357578\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.989010989010989\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[165   5]\n",
      " [  0 285]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9722222222222222\n",
      "Mejor valor de max_depth: 9\n",
      "Mejor valor de min_samples_split: 10\n",
      "Mejor score: 0.9183932193567081\n",
      "Variabes predictoras: \n",
      "['mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9802197802197802\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[167   3]\n",
      " [  6 279]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9444444444444444\n",
      "Mejor valor de max_depth: 4\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9335446247464503\n",
      "Variabes predictoras: \n",
      "['mean concave points', 'worst texture', 'worst area', 'worst smoothness']\n",
      "Tasa de acierto: 0.9824175824175824\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  2 283]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9861111111111112\n",
      "Mejor valor de max_depth: 4\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9424297305128949\n",
      "Variabes predictoras: \n",
      "['mean radius', 'mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9846153846153847\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9444444444444444\n",
      "Mejor valor de max_depth: 4\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9377644161112721\n",
      "Variabes predictoras: \n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9846153846153847\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[165   5]\n",
      " [  2 283]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9027777777777778\n",
      "Mejor valor de max_depth: 4\n",
      "Mejor valor de min_samples_split: 15\n",
      "Mejor score: 0.9253694581280788\n",
      "Variabes predictoras: \n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Tasa de acierto: 0.9868131868131869\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  0 285]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9166666666666666\n",
      "Mejor valor de max_depth: 3\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.9243371486525644\n",
      "Variabes predictoras: \n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Tasa de acierto: 0.9846153846153847\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9583333333333334\n",
      "Mejor valor de max_depth: 3\n",
      "Mejor valor de min_samples_split: 5\n",
      "Mejor score: 0.958334540712837\n",
      "Variabes predictoras: \n",
      "['mean concave points', 'worst texture', 'worst area']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[165   5]\n",
      " [  5 280]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9444444444444444\n",
      "Mejor valor de max_depth: 4\n",
      "Mejor valor de min_samples_split: 15\n",
      "Mejor score: 0.9401984931903795\n",
      "Variabes predictoras: \n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Tasa de acierto: 0.9912087912087912\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[167   3]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9583333333333334\n",
      "Mejor valor de max_depth: 5\n",
      "Mejor valor de min_samples_split: 10\n",
      "Mejor score: 0.9477434077079108\n",
      "Variabes predictoras: \n",
      "['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Tasa de acierto: 0.9912087912087912\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[167   3]\n",
      " [  1 284]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9722222222222222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de max_depth: 4\n",
      "Mejor valor de min_samples_split: 10\n",
      "Mejor score: 0.9509308895972183\n",
      "Variabes predictoras: \n",
      "['mean concave points', 'worst area']\n",
      "Tasa de acierto: 0.9648351648351648\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[163   7]\n",
      " [  9 276]]\n",
      "\n",
      "\n",
      "Sensiilidad: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for k in range(0, len(bsatras)-1, 1):\n",
    "    selected_variables = bsatras.iloc[k]['variables']  # Obtiener las variables de la mejor iteración\n",
    "    solucion = breast_cancer.loc[:, selected_variables]\n",
    "    \n",
    "    # Dividir los datos\n",
    "    X = breast_cancer[selected_variables]\n",
    "    objetivo= breast_cancer['Diagnosis']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, objetivo, test_size=.2,stratify=objetivo)\n",
    "\n",
    "    búsqueda_en_rejilla = GridSearchCV(clasificador_CART,\n",
    "                                   rejilla_de_hiperparámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "    # Obtener los mejores parámetros de la búsqueda en rejilla\n",
    "    mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "    # Guardar el valor de max_depth en una variable\n",
    "    max_depth_mejor = mejores_parametros.get('max_depth')\n",
    "    min_samples_split_mejor = mejores_parametros.get('min_samples_split')\n",
    "    mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "    print(\"Mejor valor de max_depth:\", max_depth_mejor)\n",
    "    print(\"Mejor valor de min_samples_split:\", min_samples_split_mejor)\n",
    "    print(\"Mejor score:\", mejor_score)\n",
    "\n",
    "\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    clasificador_CART = DecisionTreeClassifier(\n",
    "        max_depth=max_depth_mejor,  # Máxima profundidad del árbol\n",
    "        min_samples_split=min_samples_split_mejor  # Mínimo número de ejemplos para poder particionar\n",
    "    )\n",
    "\n",
    "    resultados_validación_cruzada = cross_validate(clasificador_CART,\n",
    "                                                X_train,\n",
    "                                                y_train,\n",
    "                                                scoring='balanced_accuracy',\n",
    "                                                cv=10)\n",
    "\n",
    "      # Ajustar el modelo\n",
    "    clasificador_CART = DecisionTreeClassifier(max_depth=4)\n",
    "    clasificador_CART.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # Calcular la Tasa de acierto del modelo\n",
    "    score = clasificador_CART.score(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones\n",
    "    predicciones = clasificador_CART.predict(X_train)\n",
    "\n",
    "    # Contar los valores de la variable objetivo\n",
    "    values = pd.Series(y_train).value_counts()\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    m_confusion = confusion_matrix(y_train, predicciones)\n",
    "\n",
    "    # Calcular la sensibilidad\n",
    "    predicciones_prueba = clasificador_CART.predict(X_test)\n",
    "    recallscore = recall_score(y_test, predicciones_prueba)\n",
    "\n",
    "    print(f'Variabes predictoras: \\n{selected_variables}')\n",
    "    print(f'Tasa de acierto: {score}')\n",
    "    print(f'Valores: {values}')\n",
    "    print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "    print()\n",
    "    print()\n",
    "    print(f'Sensibilidad: {recallscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9736263736263736\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[158  12]\n",
      " [  0 285]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 1.0\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  1 284]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9964912280701754\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'mean fractal dimension', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9758241758241758\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[160  10]\n",
      " [  1 284]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9964912280701754\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'compactness error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9758241758241758\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[160  10]\n",
      " [  1 284]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9964912280701754\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'compactness error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  1 284]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9964912280701754\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9736263736263736\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'area error', 'concave points error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points']\n",
      "Tasa de acierto: 0.9714285714285714\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  4 281]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9859649122807017\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'area error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points']\n",
      "Tasa de acierto: 0.9802197802197802\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  1 284]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9964912280701754\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean smoothness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  2 283]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9929824561403509\n",
      "Variabes predictoras: ['mean texture', 'mean concave points', 'area error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points']\n",
      "Tasa de acierto: 0.9758241758241758\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean smoothness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.967032967032967\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[158  12]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9758241758241758\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean texture', 'mean concave points', 'area error', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity']\n",
      "Tasa de acierto: 0.967032967032967\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[158  12]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean smoothness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9758241758241758\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  2 283]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9929824561403509\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'perimeter error', 'area error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  2 283]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9929824561403509\n",
      "Variabes predictoras: ['mean texture', 'mean concave points', 'worst texture', 'worst area', 'worst smoothness', 'worst concavity']\n",
      "Tasa de acierto: 0.9714285714285714\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[160  10]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean texture', 'mean concave points', 'worst texture', 'worst area', 'worst smoothness']\n",
      "Tasa de acierto: 0.967032967032967\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[158  12]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  2 283]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9929824561403509\n",
      "Variabes predictoras: ['mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9802197802197802\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabes predictoras: ['mean concave points', 'worst texture', 'worst area', 'worst smoothness']\n",
      "Tasa de acierto: 0.9692307692307692\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[160  10]\n",
      " [  4 281]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9859649122807017\n",
      "Variabes predictoras: ['mean radius', 'mean texture', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.9736263736263736\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry']\n",
      "Tasa de acierto: 0.978021978021978\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  1 284]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9964912280701754\n",
      "Variabes predictoras: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Tasa de acierto: 0.9802197802197802\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[163   7]\n",
      " [  2 283]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9929824561403509\n",
      "Variabes predictoras: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Tasa de acierto: 0.9824175824175824\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[164   6]\n",
      " [  2 283]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9929824561403509\n",
      "Variabes predictoras: ['mean concave points', 'worst texture', 'worst area']\n",
      "Tasa de acierto: 0.9714285714285714\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[161   9]\n",
      " [  4 281]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9859649122807017\n",
      "Variabes predictoras: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Tasa de acierto: 0.9758241758241758\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  3 282]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9894736842105263\n",
      "Variabes predictoras: ['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension']\n",
      "Tasa de acierto: 0.9802197802197802\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[162   8]\n",
      " [  1 284]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9964912280701754\n",
      "Variabes predictoras: ['mean concave points', 'worst area']\n",
      "Tasa de acierto: 0.9428571428571428\n",
      "Valores: Diagnosis\n",
      "1    285\n",
      "0    170\n",
      "Name: count, dtype: int64\n",
      "Matriz de confusión: \n",
      "[[156  14]\n",
      " [ 12 273]]\n",
      "\n",
      "Sensibilidad del conjunto de pruebas: 0.9578947368421052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "\n",
    "for k in range(0, len(bsatras)-1, 1):\n",
    "\n",
    "    selected_variables = bsatras.iloc[k]['variables']  # Obtiener las variables de la mejor iteración\n",
    "    solucion = breast_cancer.loc[:, selected_variables]\n",
    "\n",
    "    X = breast_cancer[selected_variables]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, objetivo, test_size=.2,stratify=objetivo)\n",
    "\n",
    "    clasificador_kNN.fit(X_train, y_train)\n",
    "    \n",
    "    búsqueda_en_rejilla = GridSearchCV(tubería_kNN,\n",
    "                                   rejilla_de_parámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1) \n",
    "\n",
    "    clasificador_kNN.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la tasa de acierto del modelo\n",
    "    score = clasificador_kNN.score(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones\n",
    "    predicciones = clasificador_kNN.predict(X_train)\n",
    "\n",
    "    # Contar los valores de la variable objetivo\n",
    "    values = pd.Series(y_train).value_counts()\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    m_confusion = confusion_matrix(y_train, predicciones)\n",
    "\n",
    "    # Calcular la sensibilidad\n",
    "    predicciones_prueba = clasificador_kNN.predict(X_train)\n",
    "    recallscore = recall_score(y_train, predicciones_prueba)\n",
    "\n",
    "    print(f'Variabes predictoras: {selected_variables}')\n",
    "    print(f'Tasa de acierto: {score}')\n",
    "    print(f'Valores: {values}')\n",
    "    print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "    print()\n",
    "    print(f'Sensibilidad del conjunto de pruebas: {recallscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo de búsqueda hacia atrás mixta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funciones.BusquedaSecuencialAtrasMixta as bsam\n",
    "busq_atras_mixta = bsam.backward_sequential_mixed_search(breast_cancer, 'Diagnosis', model, 1, 2, 10)\n",
    "busq_atras_mixta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árbol de decisión de clasificación(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for k in range(0, len(busq_atras_mixta)-1, 1):\n",
    "    selected_variables = busq_atras_mixta.iloc[k]['variables']  # Obtiener las variables de la mejor iteración\n",
    "    solucion = breast_cancer.loc[:, selected_variables]\n",
    "    # Realizar la búsqueda secuencial hacia atrás\n",
    "    model = DecisionTreeClassifier(max_depth=8)\n",
    "\n",
    "    # Dividir los datos\n",
    "    X = breast_cancer[selected_variables]\n",
    "    objetivo= breast_cancer['Diagnosis']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, objetivo, test_size=.2,stratify=objetivo)\n",
    "\n",
    "    búsqueda_en_rejilla = GridSearchCV(clasificador_kNN,\n",
    "                                   rejilla_de_hiperparámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1)  \n",
    "\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "\n",
    "    búsqueda_en_rejilla.fit(X_train, y_train)\n",
    "    # Obtener los mejores parámetros de la búsqueda en rejilla\n",
    "    mejores_parametros = búsqueda_en_rejilla.best_params_\n",
    "\n",
    "    # Guardar el valor de max_depth en una variable\n",
    "    max_depth_mejor = mejores_parametros.get('max_depth')\n",
    "    min_samples_split_mejor = mejores_parametros.get('min_samples_split')\n",
    "    mejor_score = búsqueda_en_rejilla.best_score_\n",
    "\n",
    "    print(\"Mejor valor de max_depth:\", max_depth_mejor)\n",
    "    print(\"Mejor valor de min_samples_split:\", min_samples_split_mejor)\n",
    "    print(\"Mejor score:\", mejor_score)\n",
    "\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    clasificador_CART = DecisionTreeClassifier(\n",
    "        max_depth=max_depth_mejor,  # Máxima profundidad del árbol\n",
    "        min_samples_split=min_samples_split_mejor  # Mínimo número de ejemplos para poder particionar\n",
    "    )\n",
    "\n",
    "    resultados_validación_cruzada = cross_validate(clasificador_CART,\n",
    "                                                X_train,\n",
    "                                                y_train,\n",
    "                                                scoring='balanced_accuracy',\n",
    "                                                cv=10)\n",
    "    \n",
    "    # Entrenar el modelo\n",
    "    clasificador_kNN.fit(X_train, y_train)\n",
    "\n",
    "    # Ajustar el modelo\n",
    "    clasificador_CART = DecisionTreeClassifier(max_depth=4)\n",
    "    clasificador_CART.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la Tasa de acierto del modelo\n",
    "    score = clasificador_CART.score(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones\n",
    "    predicciones = clasificador_CART.predict(X_train)\n",
    "\n",
    "    # Contar los valores de la variable objetivo\n",
    "    values = pd.Series(y_train).value_counts()\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    m_confusion = confusion_matrix(y_train, predicciones)\n",
    "\n",
    "    #Calculamos la sensibilidad\n",
    "    predicciones_prueba = clasificador_kNN.predict(X_train)\n",
    "    recallscore = recall_score(y_train, predicciones_prueba)\n",
    "\n",
    "    print(f'Variabes predictoras: \\n{selected_variables}')\n",
    "    print(f'Tasa de acierto: {score}')\n",
    "    print(f'Valores: {values}')\n",
    "    print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "    print()  \n",
    "    print()\n",
    "    print(f'Sensiilidad: {recallscore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "\n",
    "for k in range(0, len(busq_atras_mixta)-1, 1):\n",
    "\n",
    "    selected_variables = busq_atras_mixta.iloc[k]['variables']  # Obtiener las variables de la mejor iteración\n",
    "    solucion = titanic.loc[:, selected_variables]\n",
    "\n",
    "    X = titanic[selected_variables]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, objetivo, test_size=.2,stratify=objetivo)\n",
    "\n",
    "    clasificador_kNN.fit(X_train, y_train)\n",
    "    \n",
    "    búsqueda_en_rejilla = GridSearchCV(tubería_kNN,\n",
    "                                   rejilla_de_parámetros,\n",
    "                                   scoring='balanced_accuracy',\n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1) \n",
    "\n",
    "    clasificador_kNN.fit(X_train, y_train)\n",
    "\n",
    "    # Calcular la tasa de acierto del modelo\n",
    "    score = clasificador_kNN.score(X_train, y_train)\n",
    "\n",
    "    # Obtener las predicciones\n",
    "    predicciones = clasificador_kNN.predict(X_train)\n",
    "\n",
    "    # Contar los valores de la variable objetivo\n",
    "    values = pd.Series(y_train).value_counts()\n",
    "\n",
    "    # Calcular la matriz de confusión\n",
    "    m_confusion = confusion_matrix(y_train, predicciones)\n",
    "\n",
    "    # Calcular la sensibilidad\n",
    "    predicciones_prueba = clasificador_kNN.predict(X_train)\n",
    "    recallscore = recall_score(y_train, predicciones_prueba)\n",
    "\n",
    "    print(f'Variabes predictoras: {selected_variables}')\n",
    "    print(f'Tasa de acierto: {score}')\n",
    "    print(f'Valores: {values}')\n",
    "    print(f'Matriz de confusión: \\n{m_confusion}')\n",
    "    print()\n",
    "    print(f'Sensibilidad del conjunto de pruebas: {recallscore}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
