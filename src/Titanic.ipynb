{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de características para mejorar modelos predictivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este cuadernillo se realiza el tratamiento de datos del csv TITANIC, así como la implementación y comparación de varios algoritmos de búsqueda y entrenamiento.\n",
    "\n",
    "### Tratamiento de datos\n",
    "\n",
    "Se aplicaron los siguientes procesos de preprocesamiento de datos:\n",
    "\n",
    "    •Normalización de variables predictoras: Se normalizaron las variables Age y Fare utilizando el escalador MinMaxScaler para asegurar que todas las características estén en la misma escala.\n",
    "\n",
    "    •Codificación numérica de atributos discretos: Los atributos Sex, Embarked, Alone y Deck, que originalmente se presentaban como cadenas de texto, fueron codificados numéricamente utilizando las técnicas de OrdinalEncoder o LabelEncoder, según corresponda.\n",
    "\n",
    "### Algoritmos de búsqueda implementados\n",
    "\n",
    "    •Búsqueda secuencial hacia atrás (backward_sequential_search): Este algoritmo busca encontrar el mejor subconjunto de variables predictoras eliminando iterativamente la variable que más afecta el rendimiento del modelo.\n",
    "\n",
    "    •Búsqueda secuencial hacia atrás mixta (backward_sequential_search_mixto): Similar al anterior, pero también considera añadir variables si se mejora el rendimiento del modelo.\n",
    "\n",
    "### Algoritmos de entrenamiento\n",
    "\n",
    "    •Árboles de decisión de clasificación (DecisionTreeClassifier): Un algoritmo de aprendizaje supervisado utilizado para clasificación.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de atributos detectados: 13\n",
      "\n",
      "Nombres de los atributos detectados:\n",
      "['Initial' 'SibSp' 'Deck' 'Fare_cat' 'Title' 'Sex' 'Is_Married' 'Pclass'\n",
      " 'Parch' 'Embarked' 'Age_band' 'Family_Size' 'Alone']\n",
      "\n",
      "Categorías detectadas de cada atributo:\n",
      "Initial: [0 1 2 3 4]\n",
      "SibSp: [0 1 2 3 4 5 8]\n",
      "Deck: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T' 'U']\n",
      "Fare_cat: [0 1 2 3]\n",
      "Title: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Sex: ['female' 'male']\n",
      "Is_Married: [0 1]\n",
      "Pclass: [1 2 3]\n",
      "Parch: [0 1 2 3 4 5 6]\n",
      "Embarked: ['C' 'Q' 'S']\n",
      "Age_band: [0 1 2 3 4]\n",
      "Family_Size: [ 0  1  2  3  4  5  6  7 10]\n",
      "Alone: ['No' 'Yes']\n",
      "Clases detectadas: [0 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Initial</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Fare_cat</th>\n",
       "      <th>Title</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Is_Married</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age_band</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Initial     SibSp  Deck  Fare_cat   Title  Sex  Is_Married  Pclass  Parch  \\\n",
       "0     0.00  0.166667  1.00  0.000000  0.6875  1.0         0.0     1.0    0.0   \n",
       "1     0.25  0.166667  0.25  1.000000  0.7500  0.0         1.0     0.0    0.0   \n",
       "2     0.50  0.000000  1.00  0.333333  0.5000  0.0         0.0     1.0    0.0   \n",
       "3     0.25  0.166667  0.25  1.000000  0.7500  0.0         1.0     0.0    0.0   \n",
       "4     0.00  0.000000  1.00  0.333333  0.6875  1.0         0.0     1.0    0.0   \n",
       "\n",
       "   Embarked  Age_band  Family_Size  Alone       Age      Fare  Survived  \n",
       "0       1.0      0.25        0.125    0.0  0.271174  0.014151         0  \n",
       "1       0.0      0.50        0.125    0.0  0.472229  0.139136         1  \n",
       "2       1.0      0.25        0.000    1.0  0.321438  0.015469         1  \n",
       "3       1.0      0.50        0.125    0.0  0.434531  0.103644         1  \n",
       "4       1.0      0.50        0.000    1.0  0.434531  0.015713         0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import BusquedaSecuencialAtras as bsa\n",
    "import BusquedaSecuencialAtrasMixta as bsam\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "titanic.head()\n",
    "\n",
    "atributos_discretos = ['Initial', 'SibSp', 'Deck', 'Fare_cat', 'Title', 'Sex', 'Is_Married','Pclass',  'Parch', 'Embarked', \n",
    "                       'Age_band', 'Family_Size', 'Alone']\n",
    "atributos_continuos = ['Age', 'Fare']\n",
    "atributos = titanic.loc[:, atributos_discretos + atributos_continuos]\n",
    "\n",
    "objetivo = titanic['Survived']\n",
    "objetivo.head()  # objetivo es una Series unidimensional\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "codificador_atributos_discretos = OrdinalEncoder()\n",
    "codificador_atributos_discretos.fit(atributos[atributos_discretos])\n",
    "\n",
    "print('Número de atributos detectados:',\n",
    "      f'{codificador_atributos_discretos.n_features_in_}')\n",
    "print()\n",
    "print('Nombres de los atributos detectados:')\n",
    "print(f'{codificador_atributos_discretos.feature_names_in_}')\n",
    "print()\n",
    "print('Categorías detectadas de cada atributo:')\n",
    "for atributo, categorías in zip(\n",
    "    codificador_atributos_discretos.feature_names_in_,\n",
    "    codificador_atributos_discretos.categories_):\n",
    "    print(f'{atributo}: {categorías}')\n",
    "\n",
    "\n",
    "atributos[atributos_discretos] = codificador_atributos_discretos.transform(atributos[atributos_discretos])\n",
    "\n",
    "atributos.head()\n",
    "\n",
    "\n",
    "codificador_objetivo = LabelEncoder()\n",
    "# El método fit_transform ajusta el codificador a los datos y, a continuación,\n",
    "# codifica estos adecuadamente. En este caso no necesitamos mantener el\n",
    "# atributo objetivo como una Series de Pandas.\n",
    "objetivo = codificador_objetivo.fit_transform(objetivo)\n",
    "print(f'Clases detectadas: {codificador_objetivo.classes_}')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizador = MinMaxScaler(\n",
    "    # Cada atributo se normaliza al intervalo [0, 1]\n",
    "    feature_range=(0, 1)\n",
    ")\n",
    "\n",
    "# Como nos interesa conservar los atributos originales, realizamos la\n",
    "# normalización sobre una copia del DataFrame de atributos\n",
    "atributos_normalizados = atributos.copy()\n",
    "atributos_normalizados[:] = normalizador.fit_transform(atributos_normalizados)\n",
    "atributos_normalizados.head()\n",
    "\n",
    "titanic = atributos_normalizados.copy()\n",
    "titanic['Survived'] = objetivo\n",
    "titanic.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo de búsqueda hacia atrás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bsa.backward_sequential_search(titanic, 'Survived', model, 1, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo de búsqueda hacia atrás mixta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mbsam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward_sequential_mixed_search_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitanic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSurvived\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pee\\Desktop\\IA_WORKSPACE\\Proyecto\\Trabajo-IA-Modelos-Predictivos\\src\\BusquedaSecuencialAtrasMixta.py:13\u001b[0m, in \u001b[0;36mbackward_sequential_mixed_search_\u001b[1;34m(data, objective, model, N_Exp, cV, M)\u001b[0m\n\u001b[0;32m     10\u001b[0m y \u001b[38;5;241m=\u001b[39m data[objective]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Inicialización\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m current_solution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m)\n\u001b[0;32m     14\u001b[0m Añadidos \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m Eliminados \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "bsam.backward_sequential_mixed_search_(titanic, 'Survived', model, 1, 2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clasificador_CART \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m(\n\u001b[0;32m      2\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m clasificador_CART\u001b[38;5;241m.\u001b[39mfit(atributos, objetivo)\n\u001b[0;32m      7\u001b[0m pyplot\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m))  \u001b[38;5;66;03m# Anchura y altura del gráfico\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "clasificador_CART = DecisionTreeClassifier(\n",
    "    max_depth=8\n",
    ")\n",
    "clasificador_CART.fit(atributos, objetivo)\n",
    "\n",
    "\n",
    "pyplot.figure(figsize=(100, 50))  # Anchura y altura del gráfico\n",
    "árbol = plot_tree(clasificador_CART,\n",
    "                  # El argumento feature_names permite proporcionar, en una\n",
    "                  # lista, los nombres de los atributos.\n",
    "                  feature_names=atributos_discretos + atributos_continuos,\n",
    "                  # El argumento class_names permite proporcionar, en una\n",
    "                  # lista, los nombres de las clases\n",
    "                  class_names=['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones\n",
    "\n",
    "predicciones = clasificador_CART.predict(atributos)\n",
    "predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158249158249159"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificador_CART.score(atributos, objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(objetivo).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    584\n",
       "1    307\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predicciones).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasa de aciertos balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665343915343915"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = train_test_split(\n",
    "        # Conjuntos de datos a dividir, usando los mismos índices para ambos\n",
    "        atributos, objetivo,\n",
    "        # Tamaño del conjunto de prueba (20 % en este caso)\n",
    "        test_size=.2,\n",
    "        # Estratificación según la distribución de clases en el atributo objetivo\n",
    "        stratify=objetivo)\n",
    "\n",
    "\n",
    "clasificador_CART = DecisionTreeClassifier(\n",
    "    max_depth=4,  # Máxima profundidad del árbol\n",
    "    min_samples_split=5  # Mínimo número de ejemplos para poder particionar\n",
    ")\n",
    "\n",
    "resultados_validación_cruzada = cross_validate(clasificador_CART,\n",
    "                                               atributos_entrenamiento,\n",
    "                                               objetivo_entrenamiento,\n",
    "                                               scoring='recall',\n",
    "                                               cv=10)\n",
    "resultados_validación_cruzada\n",
    "\n",
    "\n",
    "resultados_validación_cruzada['test_score'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
