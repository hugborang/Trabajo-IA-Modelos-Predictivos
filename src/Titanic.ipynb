{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de características para mejorar modelos predictivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui añadimos una descripcion de lo que vamos a hacer y tal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo de búsqueda hacia atrás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de atributos detectados: 14\n",
      "\n",
      "Nombres de los atributos detectados:\n",
      "['Pclass' 'Sex' 'SibSp' 'Parch' 'Embarked' 'Initial' 'Age_band'\n",
      " 'Family_Size' 'Alone' 'Fare_cat' 'Deck' 'Title' 'Is_Married' 'Survived']\n",
      "\n",
      "Categorías detectadas de cada atributo:\n",
      "Pclass: [1 2 3]\n",
      "Sex: ['female' 'male']\n",
      "SibSp: [0 1 2 3 4 5 8]\n",
      "Parch: [0 1 2 3 4 5 6]\n",
      "Embarked: ['C' 'Q' 'S']\n",
      "Initial: [0 1 2 3 4]\n",
      "Age_band: [0 1 2 3 4]\n",
      "Family_Size: [ 0  1  2  3  4  5  6  7 10]\n",
      "Alone: ['No' 'Yes']\n",
      "Fare_cat: [0 1 2 3]\n",
      "Deck: ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'T' 'U']\n",
      "Title: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "Is_Married: [0 1]\n",
      "Survived: [0 1]\n",
      "Clases detectadas: [0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import BusquedaSecuencialAtras as bsa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "titanic = pd.read_csv('../data/titanic.csv')\n",
    "titanic.head()\n",
    "\n",
    "atributos_discretos = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked', 'Initial', 'Age_band', \n",
    "'Family_Size', 'Alone', 'Fare_cat', 'Deck', 'Title', 'Is_Married','Survived']\n",
    "atributos_continuos = ['Age', 'Fare']\n",
    "atributos = titanic.loc[:, atributos_discretos + atributos_continuos]\n",
    "\n",
    "objetivo = titanic['Survived']\n",
    "objetivo.head()  # objetivo es una Series unidimensional\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "\n",
    "codificador_atributos_discretos = OrdinalEncoder()\n",
    "codificador_atributos_discretos.fit(atributos[atributos_discretos])\n",
    "\n",
    "print('Número de atributos detectados:',\n",
    "      f'{codificador_atributos_discretos.n_features_in_}')\n",
    "print()\n",
    "print('Nombres de los atributos detectados:')\n",
    "print(f'{codificador_atributos_discretos.feature_names_in_}')\n",
    "print()\n",
    "print('Categorías detectadas de cada atributo:')\n",
    "for atributo, categorías in zip(\n",
    "    codificador_atributos_discretos.feature_names_in_,\n",
    "    codificador_atributos_discretos.categories_):\n",
    "    print(f'{atributo}: {categorías}')\n",
    "\n",
    "\n",
    "atributos[atributos_discretos] = codificador_atributos_discretos.transform(atributos[atributos_discretos])\n",
    "\n",
    "atributos.head()\n",
    "\n",
    "\n",
    "codificador_objetivo = LabelEncoder()\n",
    "# El método fit_transform ajusta el codificador a los datos y, a continuación,\n",
    "# codifica estos adecuadamente. En este caso no necesitamos mantener el\n",
    "# atributo objetivo como una Series de Pandas.\n",
    "objetivo = codificador_objetivo.fit_transform(objetivo)\n",
    "print(f'Clases detectadas: {codificador_objetivo.classes_}')\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "normalizador = MinMaxScaler(\n",
    "    # Cada atributo se normaliza al intervalo [0, 1]\n",
    "    feature_range=(0, 1)\n",
    ")\n",
    "\n",
    "# Como nos interesa conservar los atributos originales, realizamos la\n",
    "# normalización sobre una copia del DataFrame de atributos\n",
    "atributos_normalizados = atributos.copy()\n",
    "atributos_normalizados[:] = normalizador.fit_transform(atributos_normalizados)\n",
    "atributos_normalizados.head()\n",
    "\n",
    "titanic = atributos_normalizados.copy()\n",
    "titanic.head()\n",
    "result_backward = bsa.backward_sequential_search(titanic,'Survived', model, 10, 10)\n",
    "print(\"Resultado algoritmo backward:\", result_backward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Algoritmo de búsqueda hacia atrás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DecisionTreeClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clasificador_CART \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m(\n\u001b[0;32m      2\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m clasificador_CART\u001b[38;5;241m.\u001b[39mfit(atributos, objetivo)\n\u001b[0;32m      7\u001b[0m pyplot\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m50\u001b[39m))  \u001b[38;5;66;03m# Anchura y altura del gráfico\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DecisionTreeClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "clasificador_CART = DecisionTreeClassifier(\n",
    "    max_depth=8\n",
    ")\n",
    "clasificador_CART.fit(atributos, objetivo)\n",
    "\n",
    "\n",
    "pyplot.figure(figsize=(100, 50))  # Anchura y altura del gráfico\n",
    "árbol = plot_tree(clasificador_CART,\n",
    "                  # El argumento feature_names permite proporcionar, en una\n",
    "                  # lista, los nombres de los atributos.\n",
    "                  feature_names=atributos_discretos + atributos_continuos,\n",
    "                  # El argumento class_names permite proporcionar, en una\n",
    "                  # lista, los nombres de las clases\n",
    "                  class_names=['0', '1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicciones\n",
    "\n",
    "predicciones = clasificador_CART.predict(atributos)\n",
    "predicciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158249158249159"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clasificador_CART.score(atributos, objetivo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(objetivo).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    584\n",
       "1    307\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predicciones).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasa de aciertos balanceada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665343915343915"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "(atributos_entrenamiento, atributos_prueba,\n",
    " objetivo_entrenamiento, objetivo_prueba) = train_test_split(\n",
    "        # Conjuntos de datos a dividir, usando los mismos índices para ambos\n",
    "        atributos, objetivo,\n",
    "        # Tamaño del conjunto de prueba (20 % en este caso)\n",
    "        test_size=.2,\n",
    "        # Estratificación según la distribución de clases en el atributo objetivo\n",
    "        stratify=objetivo)\n",
    "\n",
    "\n",
    "clasificador_CART = DecisionTreeClassifier(\n",
    "    max_depth=4,  # Máxima profundidad del árbol\n",
    "    min_samples_split=5  # Mínimo número de ejemplos para poder particionar\n",
    ")\n",
    "\n",
    "resultados_validación_cruzada = cross_validate(clasificador_CART,\n",
    "                                               atributos_entrenamiento,\n",
    "                                               objetivo_entrenamiento,\n",
    "                                               scoring='recall',\n",
    "                                               cv=10)\n",
    "resultados_validación_cruzada\n",
    "\n",
    "\n",
    "resultados_validación_cruzada['test_score'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
